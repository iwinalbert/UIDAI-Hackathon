{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258c0e5b",
   "metadata": {},
   "source": [
    "# Aadhaar Usage Metrics Pipeline\n",
    "Ingest biometric, demographic, and enrolment CSV shards; build daily/state features; export compact JSON/CSV for UI graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69608a2a",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "- **Biometric**: bio_age_5_17, bio_age_17_ (successful biometric authentications)\n",
    "- **Demographic**: demo_age_5_17, demo_age_17_ (successful demographic authentications)\n",
    "- **Enrolment**: age_0_5, age_5_17, age_18_greater (new enrolments)\n",
    "- Keys: date, state, district, pincode\n",
    "- Visual targets: daily enrolments, biometric vs demographic usage, share ratios, child-share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "371b2cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('D:/Hackathons  & Competitions/UIDAI/Dataset/api_data_aadhar_biometric/api_data_aadhar_biometric'),\n",
       " WindowsPath('D:/Hackathons  & Competitions/UIDAI/Dataset/api_data_aadhar_demographic/api_data_aadhar_demographic'),\n",
       " WindowsPath('D:/Hackathons  & Competitions/UIDAI/Dataset/api_data_aadhar_enrolment/api_data_aadhar_enrolment'),\n",
       " WindowsPath('d:/Hackathons  & Competitions/UIDAI/Datascience/processed'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda v: f\"{v:,.3f}\")\n",
    "\n",
    "base_dir = Path.cwd()\n",
    "dataset_root = (base_dir.parent / \"Dataset\").resolve()\n",
    "biometric_dir = dataset_root / \"api_data_aadhar_biometric\" / \"api_data_aadhar_biometric\"\n",
    "demographic_dir = dataset_root / \"api_data_aadhar_demographic\" / \"api_data_aadhar_demographic\"\n",
    "enrolment_dir = dataset_root / \"api_data_aadhar_enrolment\" / \"api_data_aadhar_enrolment\"\n",
    "\n",
    "output_dir = base_dir / \"processed\"\n",
    "ui_data_dir = base_dir.parent / \"UI\" / \"src\" / \"data\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "ui_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "biometric_dir, demographic_dir, enrolment_dir, output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a68707e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1861108, 6), (2071700, 6), (1006029, 7))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_concat_csv(folder: Path, dtype_map: dict) -> pd.DataFrame:\n",
    "    files = sorted(folder.glob(\"*.csv\"))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No CSV files found in {folder}\")\n",
    "    frames = []\n",
    "    for path in files:\n",
    "        frame = pd.read_csv(\n",
    "            path,\n",
    "            dtype=dtype_map,\n",
    "            parse_dates=[\"date\"],\n",
    "            dayfirst=True,\n",
    "        )\n",
    "        frames.append(frame)\n",
    "    combined = pd.concat(frames, ignore_index=True)\n",
    "    combined.sort_values(\"date\", inplace=True)\n",
    "    combined.reset_index(drop=True, inplace=True)\n",
    "    return combined\n",
    "\n",
    "bio_dtype = {\"state\": \"category\", \"district\": \"category\", \"pincode\": \"int32\", \"bio_age_5_17\": \"int32\", \"bio_age_17_\": \"int32\"}\n",
    "demo_dtype = {\"state\": \"category\", \"district\": \"category\", \"pincode\": \"int32\", \"demo_age_5_17\": \"int32\", \"demo_age_17_\": \"int32\"}\n",
    "enrol_dtype = {\"state\": \"category\", \"district\": \"category\", \"pincode\": \"int32\", \"age_0_5\": \"int32\", \"age_5_17\": \"int32\", \"age_18_greater\": \"int32\"}\n",
    "\n",
    "bio = load_concat_csv(biometric_dir, bio_dtype)\n",
    "demo = load_concat_csv(demographic_dir, demo_dtype)\n",
    "enrol = load_concat_csv(enrolment_dir, enrol_dtype)\n",
    "\n",
    "bio.shape, demo.shape, enrol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a201ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio[\"bio_total\"] = bio[\"bio_age_5_17\"] + bio[\"bio_age_17_\"]\n",
    "demo[\"demo_total\"] = demo[\"demo_age_5_17\"] + demo[\"demo_age_17_\"]\n",
    "enrol[\"enrol_total\"] = enrol[\"age_0_5\"] + enrol[\"age_5_17\"] + enrol[\"age_18_greater\"]\n",
    "\n",
    "group_keys = [\"date\", \"state\", \"district\", \"pincode\"]\n",
    "\n",
    "bio_g = bio.groupby(group_keys, as_index=False)[[\"bio_age_5_17\", \"bio_age_17_\", \"bio_total\"]].sum()\n",
    "demo_g = demo.groupby(group_keys, as_index=False)[[\"demo_age_5_17\", \"demo_age_17_\", \"demo_total\"]].sum()\n",
    "enrol_g = enrol.groupby(group_keys, as_index=False)[[\"age_0_5\", \"age_5_17\", \"age_18_greater\", \"enrol_total\"]].sum()\n",
    "\n",
    "merged = enrol_g.merge(bio_g, on=group_keys, how=\"outer\").merge(demo_g, on=group_keys, how=\"outer\")\n",
    "merged.fillna(0, inplace=True)\n",
    "\n",
    "daily_state = merged.groupby([\"date\", \"state\"], as_index=False)[\n",
    "    [\n",
    "        \"enrol_total\",\"age_0_5\",\"age_5_17\",\"age_18_greater\",\"bio_total\",\"bio_age_5_17\",\"demo_total\",\"demo_age_5_17\"\n",
    "    ]\n",
    "].sum()\n",
    "\n",
    "denom = daily_state[\"enrol_total\"].mask(daily_state[\"enrol_total\"] == 0, np.nan)\n",
    "daily_state[\"biometric_share\"] = daily_state[\"bio_total\"].div(denom)\n",
    "daily_state[\"demographic_share\"] = daily_state[\"demo_total\"].div(denom)\n",
    "daily_state[\"child_share\"] = daily_state[\"age_0_5\"].div(denom)\n",
    "for share_col in [\"biometric_share\", \"demographic_share\", \"child_share\"]:\n",
    "    daily_state[share_col] = daily_state[share_col].fillna(0.0)\n",
    "\n",
    "bio_daily_totals = bio.groupby(\"date\", as_index=False)[[\"bio_total\", \"bio_age_5_17\", \"bio_age_17_\"]].sum()\n",
    "demo_daily_totals = demo.groupby(\"date\", as_index=False)[[\"demo_total\", \"demo_age_5_17\", \"demo_age_17_\"]].sum()\n",
    "enrol_daily_totals = enrol.groupby(\"date\", as_index=False)[[\"enrol_total\", \"age_0_5\", \"age_5_17\", \"age_18_greater\"]].sum()\n",
    "\n",
    "daily_national = (\n",
    "    enrol_daily_totals\n",
    "    .merge(bio_daily_totals, on=\"date\", how=\"outer\")\n",
    "    .merge(demo_daily_totals, on=\"date\", how=\"outer\")\n",
    "    .fillna(0)\n",
    "    .sort_values(\"date\")\n",
    ")\n",
    "\n",
    "velocity_line = (\n",
    "    daily_national.loc[:, [\"date\", \"age_0_5\", \"bio_age_5_17\"]]\n",
    "    .rename(columns={\"age_0_5\": \"enrolment_0_5\", \"bio_age_5_17\": \"biometric_5_17\"})\n",
    ")\n",
    "velocity_line_serialized = velocity_line.assign(\n",
    "    date=velocity_line[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    ").sort_values(\"date\").to_dict(\"records\")\n",
    "\n",
    "def build_ohlcv(frame: pd.DataFrame, value_col: str) -> pd.DataFrame:\n",
    "    state_daily = frame.groupby([\"date\", \"state\"], as_index=False)[value_col].sum()\n",
    "    summary = state_daily.groupby(\"date\")[value_col].agg(\n",
    "        open=lambda x: x.quantile(0.25, interpolation=\"linear\"),\n",
    "        high=\"max\",\n",
    "        low=\"min\",\n",
    "        close=lambda x: x.quantile(0.75, interpolation=\"linear\"),\n",
    "        volume=\"sum\",\n",
    "    ).reset_index()\n",
    "    summary.sort_values(\"date\", inplace=True)\n",
    "    numeric_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "    summary[numeric_cols] = summary[numeric_cols].round(0).astype(\"int64\")\n",
    "    summary[\"time\"] = summary[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    return summary[[\"time\", *numeric_cols]]\n",
    "\n",
    "velocity_ohlcv = {\n",
    "    \"biometric\": build_ohlcv(bio_g, \"bio_total\").to_dict(\"records\"),\n",
    "    \"enrolment\": build_ohlcv(enrol_g, \"enrol_total\").to_dict(\"records\"),\n",
    "    \"demographic\": build_ohlcv(demo_g, \"demo_total\").to_dict(\"records\"),\n",
    "}\n",
    "\n",
    "top_states = (\n",
    "    daily_state.groupby(\"state\", as_index=False)[[\"enrol_total\", \"bio_total\", \"demo_total\"]]\n",
    "    .sum()\n",
    "    .sort_values(\"enrol_total\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "display(daily_state.sort_values([\"date\", \"enrol_total\"], ascending=[True, False]).head())\n",
    "velocity_line.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b95edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved d:\\Hackathons  & Competitions\\UIDAI\\Datascience\\processed\\aadhaar_daily_state.csv\n",
      "Saved d:\\Hackathons  & Competitions\\UIDAI\\Datascience\\processed\\aadhaar_daily_state.json\n",
      "Mirrored to UI at d:\\Hackathons  & Competitions\\UIDAI\\UI\\src\\data\\aadhaar_daily_state.json\n",
      "Saved d:\\Hackathons  & Competitions\\UIDAI\\Datascience\\processed\\aadhaar_daily_national.csv\n",
      "Saved d:\\Hackathons  & Competitions\\UIDAI\\Datascience\\processed\\aadhaar_daily_national.json\n",
      "Mirrored to UI at d:\\Hackathons  & Competitions\\UIDAI\\UI\\src\\data\\aadhaar_daily_national.json\n",
      "Saved d:\\Hackathons  & Competitions\\UIDAI\\Datascience\\processed\\velocityData.json\n",
      "Mirrored to UI at d:\\Hackathons  & Competitions\\UIDAI\\UI\\src\\data\\velocityData.json\n",
      "Saved d:\\Hackathons  & Competitions\\UIDAI\\Datascience\\processed\\velocityDataOHLCV.json\n",
      "Mirrored to UI at d:\\Hackathons  & Competitions\\UIDAI\\UI\\src\\data\\velocityDataOHLCV.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>enrol_total</th>\n",
       "      <th>bio_total</th>\n",
       "      <th>demo_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1018629</td>\n",
       "      <td>3,555,745.000</td>\n",
       "      <td>4,144,752.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bihar</td>\n",
       "      <td>609585</td>\n",
       "      <td>1,388,218.000</td>\n",
       "      <td>2,542,380.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>493970</td>\n",
       "      <td>1,701,492.000</td>\n",
       "      <td>1,051,175.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>375297</td>\n",
       "      <td>703,820.000</td>\n",
       "      <td>1,946,152.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>369139</td>\n",
       "      <td>3,075,811.000</td>\n",
       "      <td>2,463,628.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>348458</td>\n",
       "      <td>1,432,726.000</td>\n",
       "      <td>861,710.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>280549</td>\n",
       "      <td>893,934.000</td>\n",
       "      <td>731,116.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Assam</td>\n",
       "      <td>230197</td>\n",
       "      <td>440,581.000</td>\n",
       "      <td>474,806.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>223235</td>\n",
       "      <td>537,675.000</td>\n",
       "      <td>505,536.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>220789</td>\n",
       "      <td>1,019,880.000</td>\n",
       "      <td>800,715.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state  enrol_total     bio_total    demo_total\n",
       "45   Uttar Pradesh      1018629 3,555,745.000 4,144,752.000\n",
       "6            Bihar       609585 1,388,218.000 2,542,380.000\n",
       "27  Madhya Pradesh       493970 1,701,492.000 1,051,175.000\n",
       "51     West Bengal       375297   703,820.000 1,946,152.000\n",
       "28     Maharashtra       369139 3,075,811.000 2,463,628.000\n",
       "39       Rajasthan       348458 1,432,726.000   861,710.000\n",
       "16         Gujarat       280549   893,934.000   731,116.000\n",
       "5            Assam       230197   440,581.000   474,806.000\n",
       "23       Karnataka       223235   537,675.000   505,536.000\n",
       "41      Tamil Nadu       220789 1,019,880.000   800,715.000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def write_outputs(frame: pd.DataFrame, name: str) -> None:\n",
    "    csv_path = output_dir / f\"{name}.csv\"\n",
    "    json_path = output_dir / f\"{name}.json\"\n",
    "    ui_json_path = ui_data_dir / f\"{name}.json\"\n",
    "    frame.to_csv(csv_path, index=False)\n",
    "    frame.to_json(json_path, orient=\"records\", date_format=\"iso\")\n",
    "    frame.to_json(ui_json_path, orient=\"records\", date_format=\"iso\")\n",
    "    print(f\"Saved {csv_path}\")\n",
    "    print(f\"Saved {json_path}\")\n",
    "    print(f\"Mirrored to UI at {ui_json_path}\")\n",
    "\n",
    "def write_json_payload(payload, name: str) -> None:\n",
    "    json_path = output_dir / f\"{name}.json\"\n",
    "    ui_json_path = ui_data_dir / f\"{name}.json\"\n",
    "    with json_path.open(\"w\", encoding=\"utf-8\") as handle:\n",
    "        json.dump(payload, handle, indent=2)\n",
    "    with ui_json_path.open(\"w\", encoding=\"utf-8\") as handle:\n",
    "        json.dump(payload, handle, indent=2)\n",
    "    print(f\"Saved {json_path}\")\n",
    "    print(f\"Mirrored to UI at {ui_json_path}\")\n",
    "\n",
    "write_outputs(daily_state, \"aadhaar_daily_state\")\n",
    "write_outputs(daily_national, \"aadhaar_daily_national\")\n",
    "write_json_payload(velocity_line_serialized, \"velocityData\")\n",
    "write_json_payload(velocity_ohlcv, \"velocityDataOHLCV\")\n",
    "top_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
